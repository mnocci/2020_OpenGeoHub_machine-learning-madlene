% !TeX spellcheck = en_US
%#------------------------------------------------------------------------------
%# Name:        OpenGeoHub-machine-learning-training-2.Rnw
%#              (knitr document: R + Latex)
%#
%# Inhalt:      Exercises for OpenGeoHub Summer School, 2. Series
%#
%# Author:      Madlene Nussbaum, BFH-HAFL
%# Date:        Mai 2018
%# Licence:     CC-BY-NC-SA
%#------------------------------------------------------------------------------

\documentclass[11pt,a4paper,twoside]{article}

\usepackage[utf8]{inputenc}
\usepackage{blindtext} % for blind text
\usepackage{hyperref} % links in table of contents
\usepackage[english]{babel}
\usepackage{amsthm} % for renvironment
\usepackage{natbib}
\usepackage[iso,german]{isodate}
\usepackage{subcaption}

\newtheorem{rexample}{R Example}[section]

% Some colors for the links
\definecolor{darkblue}{rgb}{0,0,0.5}
\definecolor{darkmagenta}{rgb}{0.5,0,0.5}
\definecolor{darkgreen}{rgb}{0,0.4,0}
\definecolor{darkred}{rgb}{0.7,0,0}

\hypersetup{
draft=false,
colorlinks=true,linkcolor=darkblue,citecolor=darkred,urlcolor=darkgreen,
breaklinks=true, bookmarksnumbered=true
}

% % Headers
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[OL]{\leftmark}% odd page, left
\fancyhead[OR]{\thepage}% odd page, right
\fancyhead[EL]{\thepage}% even page, left 
\fancyhead[ER]{\leftmark}% even page, right
\renewcommand{\headrulewidth}{0.4pt}
\fancyheadoffset[R]{1pt}

% captions in bold
\usepackage[font = {small}, labelfont = bf]{caption}

% format page borders
\usepackage[a4paper]{geometry}
\geometry{verbose,tmargin=2.5cm,bmargin=2.3cm,lmargin=2.5cm,rmargin=3cm,headheight=1.7cm,headsep=0.9cm,footskip=1.5cm}

% no indents
\setlength\parindent{0pt}
\setlength{\parskip}{3pt}

% Top aling logos on title page
\def\imagebox#1#2{\vtop to #1{\null\hbox{#2}\vfill}}

\newcommand{\bskip}{\vspace{0.7cm}}

\begin{document}

% % Logos
\begin{figure}
\centering
\begin{subfigure}[t]{0.27\textwidth}
% \includegraphics[width=\textwidth]{BFH-Logo.pdf}
\imagebox{37.5mm}{\includegraphics[width=\textwidth]{figure/BFH-Logo.pdf}}
\end{subfigure}
\hfill
\begin{subfigure}[t]{0.3\textwidth}
% \includegraphics[width=\textwidth]{3455_original_isric.png}
\imagebox{37.5mm}{\includegraphics[width=\textwidth]{figure/logo-opengeohub.png}}
\end{subfigure}
\end{figure}

% Title
\vspace{5cm}
{\LARGE\textsf{OpenGeoHub Summer School}}

\vspace{0.7cm}
{\Large\textbf{\textsf{Mastering Machine Learning for Spatial Prediction II} }}

\vspace{0.3cm}

{\Large\textsf{Practical training}  }

\vspace{0.5cm}
\textsf{Madlene Nussbaum,  20 August 2020}

{ \small \textsf{\copyright~ CC-BY 4.0} 	} 
\bigskip


% Table of contents (with empty back page()
\setlength{\parskip}{0pt}
\tableofcontents
\thispagestyle{empty}
\setlength{\parskip}{4pt}

% \newpage
% \mbox{}
% \thispagestyle{empty}
% \newpage

% --------


<<general-options,echo=FALSE>>=
# This code is used to generate the PDF (knitr report)
library(knitr)
# output code, but no warnings
opts_chunk$set(echo = TRUE,eval=TRUE,warning=FALSE)
# auto check dependencies (of cached chunks, its an approximation only)
opts_chunk$set(autodep = TRUE)
# dep_auto() # print dependencies 
@



\section*{Preparation}

Load needed packages:

<<load-packages,message=FALSE>>=
library(ranger) # for random forest models
library(quantregForest) # for quantile random forest
library(grpreg) # for group lasso
library(geoGAM) # for the Berne test data set
library(ggplot2) # for graphics 
library(pdp) # for partial dependence plots
@


Load again the \textsl{Berne} data, select the calibration set and remove missing values in covariates. 

<<read-in-data>>=
data(berne)
dim(berne)
# Select soil pH in 0-10 cm as continuous response, 
# select calibration data and remove rows with missing pH 
d.ph10 <- berne[ berne$dataset == "calibration" & !is.na(berne$ph.0.10), ]
d.ph10 <- d.ph10[ complete.cases(d.ph10[13:ncol(d.ph10)]), ]
# covariates start at col 13
l.covar <- names(d.ph10[, 13:ncol(d.ph10)])
@


\section{Selection of covariates}

For tree based ensemble methods covariate importance can be computed. Based on this measure non-relevant covariates can be excluded and possibly model performance can be increased. 

Fit random forest model:

<<fit-random-forest,cache=TRUE>>=
set.seed(17)
rf.ph <- ranger(x = d.ph10[, l.covar],
                y = d.ph10$ph.0.10, 
                importance = "permutation") 
@

Create the importance plot:

<<plot-covar-importance, fig.width=5, fig.height=6, fig.align='center', fig.pos="!hb", out.width='0.6\\textwidth', fig.cap="Covariate importance of 30 most important covariates for topsoil pH (before selection).">>=
# Create data frame with largest importance first
d.imp <- data.frame(variable = names(rf.ph$variable.importance), 
                    importance = rf.ph$variable.importance)
d.imp <- d.imp[order(d.imp$importance, decreasing = T), ] 
ggplot(d.imp[1:30, ], aes(x = reorder(variable, importance), 
                          y = importance, fill = importance)) + 
  geom_bar(stat = "identity", position = "dodge") + 
  coord_flip() +
  ylab("Variable Importance") +
  xlab("") +
  theme(legend.position = "none") +
  scale_fill_gradient(low = "grey", high = "darkblue")
@


Then, reduce covariates by recursive backward elimination using permuted covariate importance: 

<<select-random-forest,cache=TRUE>>=
# speed up the process by removing 5-10 covariates at a time
s.seq <- sort( c( seq(5, 95, by = 5), 
                  seq(100, length(l.covar), by = 10) ), 
               decreasing = T)

# collect results in list
qrf.elim <- oob.mse <- list()

# save model and OOB error of current fit        
qrf.elim[[1]] <- rf.ph
oob.mse[[1]] <- qrf.elim[[1]]$prediction.error
l.covar.sel <- l.covar

# Iterate through number of retained covariates           
for( ii in 1:length(s.seq) ){
  # Get importance, decreasingly ordered
  t.imp <- qrf.elim[[ii]]$variable.importance[ 
    order(qrf.elim[[ii]]$variable.importance, decreasing = T) ]

  qrf.elim[[ii+1]] <- ranger(x = d.ph10[, names(t.imp[1:s.seq[ii]])],
                             y = d.ph10$ph.0.10,
                             num.threads = 1, # set the number of CPUs
                             importance = "permutation")
  oob.mse[[ii+1]] <- qrf.elim[[ii+1]]$prediction.error
  
}

# Prepare a data frame for plot
elim.oob <- data.frame(elim.n = c(length(l.covar), s.seq[1:length(s.seq)]), 
                       elim.OOBe = unlist(oob.mse) )
@

<<plot-selection-path,fig.align='center',echo=FALSE,fig.height = 5,out.width='0.8\\textwidth',fig.cap = "Path of out-of-bag mean squared error as covariates are removed. Minimum is found at 55 covariates.">>=

plot(elim.oob$elim.n, elim.oob$elim.OOBe, 
     ylab = "OOB error (MSE)",
     xlab = "n covariates", 
     pch = 20)
abline(v = elim.oob$elim.n[ which.min(elim.oob$elim.OOBe)], lty = "dotted")
@


\paragraph{Please continue:}

\begin{itemize}
\item Optimize m$_{try}$ before you start the covariate selection (function \texttt{train}, package \texttt{caret}). How much does the OOB error decrease? Are both steps (tuning, selection) worth the effort from a point of view of prediction performance?
\item Implement the same covariate selection for gradient boosting with trees as baselearners (package \texttt{gbm} or \texttt{caret}). Do you find the same covariates in the final set? Why do you expect differences?
\end{itemize}


\section{Model interpretation}
\subsection{Partial resiudal plots}

To demonstrate the principle we create a partial residual plot for an ordinary least squares fit. Then, we add the same plot for the lasso fitted on the topsoil pH data above:    

<<partial-residual-plots-lm-lasso,fig.width=7,fig.height=4, fig.align='center', out.width='0.9\\textwidth',fig.cap = "Partial residual plots for a climate covariate in the ordinary least squares fit and the lasso.">>=
# create a linear model (example, with covariates from lasso)
ols <- lm( ph.0.10 ~ timeset + ge_geo500h3id + cl_mt_gh_4 + 
             tr_se_curvplan2m_std_25c, data = d.ph10 ) 
par(mfrow = c(1,2)) # two plots on same figure
# residual plot for covariate cl_mt_gh_4
termplot(ols, partial.resid = T, terms = "cl_mt_gh_4",
         ylim = c(-2,2),
         main = "Ordinary Least Squares")
abline(h=0, lty = 2)

## Create partial residual plot for lasso 
# there is no direct function available, but we can easily 
# construct the plot with
# y-axis: residuals + effect of term (XBi), scaled
# x-axis: values covariate
# regression line: model fit of axis y~x 

## First setup and fit the model 
l.factors <- names(d.ph10[l.covar])[ 
  t.f <- unlist( lapply(d.ph10[l.covar], is.factor) ) ]
l.numeric <-  names(t.f[ !t.f ])
# create a vector that labels the groups with the same number  
g.groups <- c( 1:length(l.numeric), 
               unlist( 
                 sapply(1:length(l.factors), function(n){
                   rep(n+length(l.numeric), nlevels(d.ph10[, l.factors[n]])-1)
                 }) 
               ) 
)
# grpreg needs model matrix as input
XX <- model.matrix( ~., d.ph10[, c(l.numeric, l.factors), F])[,-1]
# cross validation (CV) to find lambda
ph.cvfit <- cv.grpreg(X = XX, y = d.ph10$ph.0.10, 
                      group = g.groups, 
                      penalty = "grLasso",
                      returnY = T) # access CV results
# choose optimal lambda: CV minimum error + 1 SE (see glmnet)
l.se <- ph.cvfit$cvse[ ph.cvfit$min ] + ph.cvfit$cve[ ph.cvfit$min ]
idx.se <- min( which( ph.cvfit$cve < l.se ) ) - 1

# get the non-zero coefficients:
t.coef <- ph.cvfit$fit$beta[, idx.se ]

# get the index of the covariate
idx <- which( names(t.coef) == "cl_mt_gh_4" )

# residuals of lasso model chosen above
residuals <- d.ph10$ph.0.10 - ph.cvfit$Y[,idx.se] 
# prediction for this covariate XBi
Xbeta <- ph.cvfit$fit$beta[idx, idx.se] * d.ph10$cl_mt_gh_4
# calculate partial residuals and center with mean
part.resid <- scale(residuals + Xbeta, scale = F)[,1]

# plot with similar settings
plot(d.ph10$cl_mt_gh_4, 
     part.resid, pch = 1, col = "grey",
     ylim = c(-2,2),
     ylab = "partial residuals [%]", xlab = "cl_mt_gh_4",
     main = "Lasso")
abline(lm(part.resid ~ d.ph10$cl_mt_gh_4), col = "red")
abline(h=0, lty = 2)
@



\clearpage
\subsection{Partial dependence plots}

Interpretation of the most important covariates of a random forest model can be done by partial dependence plots. But keep in mind that the remaining covariates after model selection might be still multi-collinear, hence covariates might be exchangeable.

Partial dependence plots are a general method and can be also applied to other supervised machine learning methods. 

<<partial-dep-rf,fig.width=7,fig.height=8, fig.align='center', out.width='0.9\\textwidth',fig.cap = "Partial dependence plots for the 4 most important covariates.">>=
# select the model with minimum OOB error
rf.selected <- qrf.elim[[ which.min(elim.oob$elim.OOBe)]]

t.imp <- rf.selected$variable.importance[ 
  order(rf.selected$variable.importance, decreasing = T)]

# 6 most important covariates
t.6 <- names( t.imp[ 1:6 ] )

# Create partial dependence plots for the 6 most important covariates 
# list with 6 plots
l.plots <- lapply(t.6, 
                  function(n.var){ 
                    plotPartial(partial(rf.selected, 
                                        pred.var = n.var, 
                                        train = d.ph10)) 
                    } 
                  )
# Create layout for the resulting trellis plots (Package lattice)
grid.arrange(l.plots[[1]], l.plots[[2]], l.plots[[3]], 
             l.plots[[4]], l.plots[[5]], l.plots[[6]], ncol = 2)
@


\paragraph{Please continue:}

\begin{itemize}
\item Create partial dependence plots for the boosted trees model (\texttt{?plot.gbm}, \texttt{plot(.., i.var = ..)}). Do you find the same relationships?
\item What do you conclude from the plots? Are the plotted covariates good predictors?
\end{itemize}


\clearpage 
\section{Prediction uncertainty with quantile regression forest}

When reporting predictions it is important to give prediction uncertainty along with them. For any method not yielding uncertainty estimates form the method itself (e.g. kriging variances) a non-parametric or a model-based bootstrap approach can be used. Quantile regression forest computes quantiles of the predictions directly from the bootstrap (bootstrap aggregation, bagging) that is done within random forest. 

<<quantRF,cache=TRUE>>=
# Fit quantile regression forest 
ph.quantRF <- ranger(x = d.ph10[, l.covar[1:30]],
                     y = d.ph10$ph.0.10,
                     quantreg = T) 

# select validation data
d.ph10.val <- berne[berne$dataset == "validation" & !is.na(berne$ph.0.10), ]
d.ph10.val <- d.ph10.val[complete.cases(d.ph10.val[l.covar]), ]

# compute predictions (mean) for each validation site
ph.pred <- predict(ph.quantRF, data = d.ph10.val, what = mean)
@

<<investigate-single-point,echo=FALSE,fig.pos='!h',fig.height=5,fig.width=4,fig.align='center', out.width='0.4\\textwidth',fig.cap= "Histogram of predictive distribution for one single prediction point (dotted lines: 90 \\% prediction interval, dashed line: mean prediction).">>=

## predict 0.01, 0.02,..., 0.99 quantiles for validation data
ph.pred.distribution <- predict(ph.quantRF,
                                data = d.ph10.val, 
                                type = "quantiles",
                                quantiles = seq(0.01, 0.99, by = 0.01))

# plot predictive distribution for one site
sel.site <- 12
hist( ph.pred.distribution$predictions[sel.site,], 
      col = "grey", main = "",
      xlab = "predicted pH [-]", breaks = 12)

# add 90 % prediction interval and mean (dashed) to plot
abline(v = c( ph.pred.distribution$predictions[sel.site, "quantile= 0.05"],
              ph.pred.distribution$predictions[sel.site, "quantile= 0.95"]), 
       lty = "dotted")
abline(v = ph.pred$predictions[sel.site], lty = "dashed")
@


Plot for evaluation of prediction intervals (as shown in presentation):  

% Code based on A. Papritz
<<create-intervall-plot,fig.height=5,fig.align='center',echo=FALSE, out.width='0.8\\textwidth',fig.cap= "Coverage of 90 \\%-prediction intervals computed by model-based boostrap.">>=

# get 90% quantiles for each point
t.quant90 <- cbind( 
  ph.pred.distribution$predictions[, "quantile= 0.05"],
  ph.pred.distribution$predictions[, "quantile= 0.95"])

# get index for ranking in the plot
t.ix <- sort( ph.pred$predictions, index.return = T )$ix

# plot predictions in increasing order
plot(
  ph.pred$predictions[t.ix], type = "n",
  ylim = range(c(t.quant90, ph.pred$predictions, d.ph10.val$ph.0.10)),
  xlab = "rank of predictions", 
  ylab =  "ph [-]" 
) 

# add prediction intervals
segments(
  1:nrow( d.ph10.val ),
  t.lower <- (t.quant90[,1])[t.ix],
  1:nrow( d.ph10.val ),
  t.upper <- (t.quant90[,2])[t.ix],
  col = "grey"
)

# select colour for dots outside of intervals
t.col <- sapply(
  1:length( t.ix ),
  function( i, x, lower, upper ){
    as.integer( cut( x[i], c( -Inf, lower[i]-0.000001, 
                              x[i], upper[i]+0.000001, Inf ) ) )
  },
  x = d.ph10.val$ph.0.10[t.ix],
  lower = t.lower, upper = t.upper
)

# add observed values on top 
points(
  1:nrow( d.ph10.val ),
  d.ph10.val$ph.0.10[t.ix], cex = 0.7,
  pch = c( 16, 1, 16)[t.col],
  col = c( "darkgreen", "black", "darkgreen" )[t.col]
)
points(ph.pred$predictions[t.ix], pch = 16, cex = 0.6, col = "grey60")

# Add meaningfull legend
legend( "topleft", 
        bty = "n", cex = 0.85,
        pch = c( NA, 16, 1, 16 ), pt.cex = 0.6, lwd = 1,
        lty = c( 1, NA, NA, NA ), 
        col = c( "grey", "grey60", "black", "darkgreen" ), 
        seg.len = 0.8,
        legend = c(
          "90 %-prediction interval", 
          paste0("prediction (n = ", nrow(d.ph10.val), ")"),
          paste0("observation within interval (n = ", 
                 sum( t.col %in% c(2) ), ")" ),
          paste0("observation outside interval (n = ", 
                 sum( t.col %in% c(1,3)), ", ", 
                 round(sum(t.col %in% c(1,3)) / 
                         nrow(d.ph10.val)*100,1), "%)") )
)
@



<<create-coverage-probabilty-plots,fig.align='center', fig.pos = "h", fig.width=4,fig.height=4.5, out.width='0.45\\textwidth',fig.cap="Coverage probabilities of one-sided prediction intervals computed for the validation data set of topsoil pH of the Berne study area.">>=

# Coverage probabilities plot
# create sequence of nominal probabilities 
ss <- seq(0,1,0.01)
# compute coverage for sequence
t.prop.inside <- sapply(ss, function(ii){
  boot.quantile <-  t( apply(ph.pred.distribution$predictions, 1, quantile, 
                             probs = c(0,ii) ) )[,2]
  return( sum(boot.quantile <= d.ph10.val$ph.0.10)/nrow(d.ph10.val) )
})

plot(x = ss, y = t.prop.inside[length(ss):1], 
     type = "l", asp = 1,
     ylab = "coverage probabilities", 
     xlab="nominal probabilities" )
# add 1:1-line  
abline(0,1, lty = 2, col = "grey60")
# add lines of the two-sided 90 %-prediction interval
abline(v = c(0.05, 0.95), lty = "dotted", col = "grey20")
@


\paragraph{Please continue:}

\begin{itemize}
\item Are you satisfied with the prediction intervals? 
\item Create maps of the prediction intervals for the \texttt{berne.grid} data. Is there much spatial structure in the uncertainty? 
\end{itemize}



\bigskip 
\section*{R session information}

\footnotesize
This document was generated with:
<<session-info,results='asis'>>=
toLatex(sessionInfo(), locale = FALSE)
@
\normalsize

<<export-r-code,echo=FALSE,result="hide">>=
# purl("OpenGeoHub-machine-learning-training-2.Rnw")
@


\end{document}
